{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性模型\n",
    "\n",
    "> $ f(\\bf{x}) = \\bf{\\omega}^T\\bf{x} + b $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 生成数据集\n",
    "# y = lambda^T * x + b\n",
    "import numpy as np\n",
    "\n",
    "lambdas = np.array([0.4, 0.6, 0.1])\n",
    "b = 0.7\n",
    "\n",
    "x = np.array(\n",
    "    [[0.1, 0.3, 0.6],\n",
    "    [0.5, 0.7, 0.1],\n",
    "    [0.9, 1.1, 3.1],\n",
    "    [0.1, 0.5, 0.3],\n",
    "    [0.9, 0.1, 0.0],\n",
    "    [0.0, 0.3, -0.3],\n",
    "    [0.3, 0.5, 0.1],\n",
    "    [-0.5, 0.6, 0.2]])\n",
    "\n",
    "y = np.dot(x, lambdas)+ b+ (np.random.rand(8)-0.5)*0.001\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最小二乘法\n",
    "\n",
    "> $ (\\omega^*, b^*) = argmin_{(\\omega,b)}\\sum_{i=1}^{m}(y_i-\\omega x_i-b)^2 $\n",
    "\n",
    "> $ \\omega = \\omega + \\alpha * (\\omega \\sum_{i=1}^{m}x_i^2 - \\sum_{i=1}^{m}(y_i-b)x_i) $\n",
    "\n",
    "> $ b = b + \\alpha * (mb - \\sum_{i=1}^{m}(y_i-\\omega x_i)) $\n",
    "\n",
    "#### 向量形式\n",
    "\n",
    "> $ \\omega^* = argmin_{\\omega}(y-X\\omega)^T(y-X\\omega) $\n",
    "\n",
    "> $ \\omega = \\omega + X^T(X\\omega - y) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.14068681  0.55193034  0.45331055  0.62897826]\n",
      "[ 0.3957395   0.5793193   0.10530232  0.70923767]\n",
      "[ 0.39942186  0.597373    0.10054259  0.70119047]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.39997287,  0.60007552,  0.09983014,  0.6999859 ])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def least_square_method(x, y, a=0.01, eps=1e-9, maxstep=1000):\n",
    "    X = np.concatenate([x, np.ones((x.shape[0],1))], axis=1)\n",
    "    w = np.random.rand(X.shape[1])\n",
    "    w_0 = np.zeros(X.shape[1])\n",
    "    step = 0\n",
    "    obj_0 = 0\n",
    "    obj = np.sum( (np.dot(X, w) - y)**2 )\n",
    "    while (np.abs(obj_0-obj) > eps and step < maxstep):\n",
    "        w_0 = w.copy()\n",
    "        obj_0 = obj\n",
    "        w = w - a * (np.dot(X.T, np.dot(X, w)-y))\n",
    "        obj = np.sum( (np.dot(X, w) - y)**2 )\n",
    "        # print (np.sum((w_0-w)**2))\n",
    "        if step%(maxstep//100) ==0:\n",
    "            print(w)\n",
    "        step += 1\n",
    "    return w\n",
    "        \n",
    "least_square_method(x,y,maxstep=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对数几率回归 logistic regression\n",
    "\n",
    "> 不要轻易翻译为逻辑回归\n",
    "\n",
    "> $ y = \\frac{1}{1+e^{-z}} $\n",
    "\n",
    "> 建立对数似然函数之后，求导得：\n",
    "\n",
    "> $ \\frac{\\partial L}{\\partial \\theta} = \\sum_{i=1}^{m} (y_i-\\sigma(\\theta^T x_i))x_i $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.47268674184 [-0.50324329 -0.00509019  0.85025005]\n",
      "2.13259928572 [-0.19212312 -0.05048716  0.22859254]\n",
      "2.19434270715 [-0.07080534 -0.02847948  0.05838228]\n",
      "2.2365926134 [-0.02458731 -0.01127324  0.01711192]\n",
      "2.25324557002 [-0.00833436 -0.00405399  0.00548152]\n",
      "2.25911111708 [-0.00280117 -0.00141635  0.00182136]\n",
      "2.26110885598 [-0.00093859 -0.00049048  0.00061326]\n",
      "2.26178178776 [-0.00031411 -0.00016944  0.00020747]\n",
      "2.2620075946 [ -1.05051433e-04  -5.85087959e-05   7.03137855e-05]\n",
      "2.26208325563 [ -3.51183477e-05  -2.02092490e-05   2.38502032e-05]\n",
      "2.26210859057 [ -1.17353153e-05  -6.98378321e-06   8.09408162e-06]\n",
      "2.2621170705 [ -3.91998485e-06  -2.41475368e-06   2.74804685e-06]\n",
      "2.2621199079 [ -1.30886745e-06  -8.35420461e-07   9.33363282e-07]\n",
      "2.262120857 [ -4.36835726e-07  -2.89193868e-07   3.17136988e-07]\n",
      "2.26212117437 [ -1.45726876e-07  -1.00166786e-07   1.07799268e-07]\n",
      "Total step: 1453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.02787742,  0.24836482,  0.29922371])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdb\n",
    "\n",
    "def sigma(X):\n",
    "    return 1/(1+np.e**(-X))\n",
    "    \n",
    "def logistic_regression(x, y, a=0.01, eps=1e-9, maxstep=1000, lambdas=0.8):\n",
    "    dim = x.shape[1]\n",
    "    theta = np.random.rand(dim)\n",
    "    theta_0 = np.zeros(dim)\n",
    "    obj = np.sum( (sigma(np.dot(x, theta)) -y)**2 ) + lambdas * np.sum(theta**2)\n",
    "    obj_0 = 0\n",
    "    step = 0\n",
    "    while (np.abs(obj-obj_0) > eps) and step < maxstep:\n",
    "        theta_0 = theta\n",
    "        obj_0 = obj\n",
    "        delta = np.dot((sigma(np.dot(x, theta)) - y) ,x) + lambdas * theta\n",
    "        theta = theta - a * delta\n",
    "        obj = np.sum( (sigma(np.dot(x, theta)) -y)**2 ) + lambdas * np.sum(theta**2)\n",
    "        if step % (maxstep//100) == 0:\n",
    "            print(obj, delta)\n",
    "        step +=1\n",
    "    print(\"Total step: %s\" % step)\n",
    "    return theta\n",
    "        \n",
    "y_logistic = (y > 1).astype('int')\n",
    "logistic_regression(x, y_logistic, a=0.01, eps=1e-9, maxstep=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.87608388,  0.21525248,  0.28978609]])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn\n",
    "import sklearn.linear_model\n",
    "lr = sklearn.linear_model.LogisticRegression(verbose=1, random_state=np.random.randint(1000000), warm_start=True)\n",
    "lr.fit(x, y_logistic)\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [ml]",
   "language": "python",
   "name": "Python [ml]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

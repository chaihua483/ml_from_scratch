{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性模型\n",
    "\n",
    "> $ f(\\bf{x}) = \\bf{\\omega}^T\\bf{x} + b $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 生成数据集\n",
    "# y = lambda^T * x + b\n",
    "import numpy as np\n",
    "\n",
    "lambdas = np.array([0.4, 0.6, 0.1])\n",
    "b = 0.7\n",
    "\n",
    "x = np.array(\n",
    "    [[0.1, 0.3, 0.6],\n",
    "    [0.5, 0.7, 0.1],\n",
    "    [0.9, 1.1, 3.1],\n",
    "    [0.1, 0.5, 0.3],\n",
    "    [0.9, 0.1, 0.0],\n",
    "    [0.0, 0.3, -0.3],\n",
    "    [0.3, 0.5, 0.1],\n",
    "    [-0.5, 0.6, 0.2]])\n",
    "\n",
    "y = np.dot(x, lambdas)+ b+ (np.random.rand(8)-0.5)*0.001\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最小二乘法\n",
    "\n",
    "> $ (\\omega^*, b^*) = argmin_{(\\omega,b)}\\sum_{i=1}^{m}(y_i-\\omega x_i-b)^2 $\n",
    "\n",
    "> $ \\omega = \\omega + \\alpha * (\\omega \\sum_{i=1}^{m}x_i^2 - \\sum_{i=1}^{m}(y_i-b)x_i) $\n",
    "\n",
    "> $ b = b + \\alpha * (mb - \\sum_{i=1}^{m}(y_i-\\omega x_i)) $\n",
    "\n",
    "#### 向量形式\n",
    "\n",
    "> $ \\omega^* = argmin_{\\omega}(y-X\\omega)^T(y-X\\omega) $\n",
    "\n",
    "> $ \\omega = \\omega + X^T(X\\omega - y) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.42551761  0.47890737  0.20751749  0.18229606]\n",
      "[ 0.40248517  0.61171114  0.09687605  0.69461181]\n",
      "[ 0.40055201  0.60223152  0.0993752   0.69883716]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.40037093,  0.60134342,  0.09960933,  0.69923301])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def least_square_method(x, y, a=0.01, eps=1e-9, maxstep=1000):\n",
    "    X = np.concatenate([x, np.ones((x.shape[0],1))], axis=1)\n",
    "    w = np.random.rand(X.shape[1])\n",
    "    w_0 = np.zeros(X.shape[1])\n",
    "    step = 0\n",
    "    obj_0 = 0\n",
    "    obj = np.sum( (np.dot(X, w) - y)**2 )\n",
    "    while (np.abs(obj_0-obj) > eps and step < maxstep):\n",
    "        w_0 = w.copy()\n",
    "        obj_0 = obj\n",
    "#         print (obj)\n",
    "        w = w - a * (np.dot(X.T, np.dot(X, w)-y))\n",
    "        obj = np.sum( (np.dot(X, w) - y)**2 )\n",
    "        # print (np.sum((w_0-w)**2))\n",
    "        if step%(maxstep//100) ==0:\n",
    "            print(w)\n",
    "        step += 1\n",
    "    return w\n",
    "        \n",
    "least_square_method(x,y,maxstep=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对数几率回归 logistic regression\n",
    "\n",
    "> 不要轻易翻译为逻辑回归\n",
    "\n",
    "> $ y = \\frac{1}{1+e^{-z}} $\n",
    "\n",
    "> 建立对数似然函数之后，求导得：\n",
    "\n",
    "> $ \\frac{\\partial L}{\\partial \\theta} = \\sum_{i=1}^{m} (y_i-\\sigma(\\theta^T x_i))x_i $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.76156376608 [-0.60982513  0.75410824  0.82503003]\n",
      "2.11587137965 [-0.24958155  0.18703911  0.17256454]\n",
      "2.17849185539 [-0.09462561  0.0500452   0.02909496]\n",
      "2.22994792946 [-0.03338863  0.01594953  0.00595353]\n",
      "2.25075640888 [-0.01150388  0.00551054  0.00148642]\n",
      "2.25820632766 [-0.00393568  0.00195551  0.00041047]\n",
      "2.26078317092 [-0.00134393  0.00069928  0.00011655]\n",
      "2.26166498899 [ -4.58803038e-04   2.50480105e-04   3.27051605e-05]\n",
      "2.26196578085 [ -1.56671834e-04   8.97110674e-05   8.82442859e-06]\n",
      "2.26206830245 [ -5.35236374e-05   3.21110249e-05   2.21238070e-06]\n",
      "2.26210324747 [ -1.82943300e-05   1.14854969e-05   4.78560953e-07]\n",
      "2.26211516262 [ -6.25625531e-06   4.10520321e-06   6.72916748e-08]\n",
      "2.26211922708 [ -2.14064868e-06   1.46630471e-06  -1.04439742e-08]\n",
      "2.26212061419 [ -7.32847345e-07   5.23403751e-07  -1.51972342e-08]\n",
      "2.26212108782 [ -2.51028107e-07   1.86719871e-07  -9.23945348e-09]\n",
      "Total step: 1492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.0278774 ,  0.24836494,  0.29922365])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdb\n",
    "\n",
    "def sigma(X):\n",
    "    return 1/(1+np.e**(-X))\n",
    "    \n",
    "def logistic_regression(x, y, a=0.01, eps=1e-9, maxstep=1000, lambdas=0.8):\n",
    "    dim = x.shape[1]\n",
    "    theta = np.random.rand(dim)\n",
    "    theta_0 = np.zeros(dim)\n",
    "    obj = np.sum( (sigma(np.dot(x, theta)) -y)**2 ) + lambdas * np.sum(theta**2)\n",
    "    obj_0 = 0\n",
    "    step = 0\n",
    "    while (np.abs(obj-obj_0) > eps) and step < maxstep:\n",
    "        theta_0 = theta\n",
    "        obj_0 = obj\n",
    "        delta = np.dot((sigma(np.dot(x, theta)) - y) ,x) + lambdas * theta\n",
    "        theta = theta - a * delta\n",
    "        obj = np.sum( (sigma(np.dot(x, theta)) -y)**2 ) + lambdas * np.sum(theta**2)\n",
    "        if step % (maxstep//100) == 0:\n",
    "            print(obj, delta)\n",
    "        step +=1\n",
    "    print(\"Total step: %s\" % step)\n",
    "    return theta\n",
    "        \n",
    "y_logistic = (y > 1).astype('int')\n",
    "logistic_regression(x, y_logistic, a=0.01, eps=1e-9, maxstep=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][[ 0.87608388  0.21525248  0.28978609]]\n",
      "[ 0.0376202]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn\n",
    "import sklearn.linear_model\n",
    "lr = sklearn.linear_model.LogisticRegression(verbose=1, random_state=np.random.randint(1000000), warm_start=True)\n",
    "lr.fit(x, y_logistic)\n",
    "print (lr.coef_)\n",
    "print (lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [ml]",
   "language": "python",
   "name": "Python [ml]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
